{
  "hash": "ec47ad9c8512fa12c3dcebf043c86fd9",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Observational Studies and Causal Diagrams\"\ndate: \"TBD\"\nimage: thumbnail.png\n---\n\n\n::: {.callout-warning}\n## Disclaimer\nThis blog post was written solely for informational and educational purposes, and does not constitute medical advice. If you have any health concerns, please consult a qualified medical professional.\n:::\n\nRandomised Controlled Trials (RCTs) are widely recognised as the gold standard of study designs, but they are not always possible to perform. For example, it would have been neither ethical nor feasible for Richard Doll and Austin Bradford Hill to randomly assign a group of volunteers to a smoking and non-smoking group in order to show that cigarettes causes lung cancer. However, they were still able to establish a link between smoking and the disease, using first a case-control study and then a prospective cohort study[^1].\n\nThese are both types of observational study[^2] -- an alternative to RCTs that can be very useful, as in the case of smoking and lung cancer. Unfortunately, the fact the participants are not randomised to different groups in observational studies can make their results particularly difficult to interpret. In this article, I will discuss how diagrams representing causal relationships can help us to spot potential sources of bias in these kinds of studies. \n\n## Causal Inference\n\nCausal relationships are notoriously difficult to distinguish from mere statistical associations, as summed up in the famous saying \"correlation does not imply causation\". A humorous example of this can be found in an educational statistics paper in which the author investigates the fairy tale that storks deliver babies by analysing data on stork populations and birth rates for European countries(CITE -- PAPER_robert-matthew_storks-deliver-babies).\n\nDATA\n\nWe can plot these data and observe a linear relationship between stork populations and birth rates, with a correlation coefficient of .\n\n\n\n::: {.cell}\n\n:::\n\n\n\nMoreover, performing a statistical test for the null hypothesis that there is no relationship between stork populations and birth rates gives us a p-value of less than 0.05, a common threshold for a result to be considered statistically significant.(CITE -- introduction to medical statistics?).\n\n\n\n::: {.cell}\n\n:::\n\n\n\nClearly, more storks do not cause more babies to be born. But the non-causality of statistical associations might not always be so obvious. To deal with the challenges of understanding causes and effects, a new branch of statistics known as 'causal inference' has emerged over the past few decades(CITE -- book of why). \n\nOne of the main techniques of causal inference is the use of directed acyclic graphs -- 'DAGs' for short -- to model the relationships between variables. Let's explore the essential features of these diagrams.\n\n### Directed Acyclic Graphs\n\nIn discrete mathematics, a **graph** is a structure made up of vertices linked by edges. A path between two vertices is a sequence of edges linking them together(CITE -- PAPER_sander-greenland-and-judea-pearl_causal-diagrams).\n\n![](example-graph.png)\n\nFor example, in the above graph, there is a path between A and C along the vertices A,B,D,E,C. \n\n**Directed** graphs are a particular type of graph in which all the edges are arrows. Definition of ancestors parents and children (CITE -- BOOK_pearl-et-al_causal-inference-a-primer).\n\n![](example-dag.png)\n\nHere, B is a parent of C, and D, a child of A, and and ancestor of E.\n\nDirected graphs are ideal for causal inference, because we can use vertices the to represent variables and edges to represent the causal relationships between them, with parents having a direct effect on their children. For example, a simplified DAG showing the effect of different factors on a person's chance of developing lung cancer might show the variables 'Genetics', 'Environmental Factors', and 'Smoking' all to be parents of the variable 'Lung Cancer Risk'.\n\n![](smoking-dag)\n\nAn **acyclic** graph is simply one that contains no cycles (a cycle is a directed path leading from a variable back to itself), so when we use a DAG to model causal relationships a variable cannot cause itself.\n\nAn example of a DAG which might explain the correlation between the stork populations and birth rates of European country could introduce extra variables, such as land area and human population size. \n\n![](storks-dag.png)\n\nThis DAG could account for the association between the 'Stork Population' and 'Birth Rate' variables without requiring there to be a causal relationship between them; their correlation can be explained by the fact that 'Land Area' is both a parent of 'Stork Population' and an ancestor of 'Birth Rate'. \n\nThere are several structures that commonly appear appear in DAGs representing observational studies. In the rest of this article I want to focus on two of the most important -- **confounders** and **colliders** -- and explore how both of them can help to explain misleading results in medical research. \n\n## Confounders\n\nIn our storks and babies example, land area is actually a confounder. What is the structure of a counfounder. Robert Heaton's example. Kidney stones.\n\n![](example-confounder.png)\n\n![](confounditis-dag.png)\n\n![](kidney-stones-dag.png)\n\n## Colliders\n\n![](example-collider.png)\n\n![](colliditis-dag.png)\n\n![](pancreatic-cancer-dag.png)\n\n[^1]: Jonathan Wood, [\"Life of a revolutionary,\"](https://www.ox.ac.uk/news/science-blog/life-revolutionary) OxSciBlog, November 11, 2009.\n[^2]: [\"Study designs,\"](https://www.cebm.ox.ac.uk/resources/ebm-tools/study-designs) Centre for Evidence-Based Medicine, May 29, 2020.\n[^3]: Storks and babies",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}